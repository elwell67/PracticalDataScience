{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Learning Using Random Forests\n",
    "This a lab session to use tree ensembles, in particular Random Forests, to build a interesting classifier related to human activity recognition using mobile phone data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Documentation about the Data Sources\n",
    "\n",
    "The features selected for this UCI database come from the accelerometer and gyroscope 3-axial raw signals tAcc-XYZ and tGyro-XYZ. These time domain signals (prefix 't' to denote time) were captured at a constant rate of 50 Hz. Then they were filtered using a median filter and a 3rd order low pass Butterworth filter with a corner frequency of 20 Hz to remove noise. Similarly, the acceleration signal was then separated into body and gravity acceleration signals (tBodyAcc-XYZ and tGravityAcc-XYZ) using another low pass Butterworth filter with a corner frequency of 0.3 Hz. \n",
    "\n",
    "Subsequently, the body linear acceleration and angular velocity were derived in time to obtain Jerk signals (tBodyAccJerk-XYZ and tBodyGyroJerk-XYZ). Also the magnitude of these three-dimensional signals were calculated using the Euclidean norm (tBodyAccMag, tGravityAccMag, tBodyAccJerkMag, tBodyGyroMag, tBodyGyroJerkMag). \n",
    "\n",
    "Finally a Fast Fourier Transform (FFT) was applied to some of these signals producing fBodyAcc-XYZ, fBodyAccJerk-XYZ, fBodyGyro-XYZ, fBodyAccJerkMag, fBodyGyroMag, fBodyGyroJerkMag. (Note the 'f' to indicate frequency domain signals). \n",
    "\n",
    "These signals were used to estimate variables of the feature vector for each pattern:  \n",
    "'-XYZ' is used to denote 3-axial signals in the X, Y and Z directions.\n",
    "\n",
    "tBodyAcc-XYZ\n",
    "tGravityAcc-XYZ\n",
    "tBodyAccJerk-XYZ\n",
    "tBodyGyro-XYZ\n",
    "tBodyGyroJerk-XYZ\n",
    "tBodyAccMag\n",
    "tGravityAccMag\n",
    "tBodyAccJerkMag\n",
    "tBodyGyroMag\n",
    "tBodyGyroJerkMag\n",
    "fBodyAcc-XYZ\n",
    "fBodyAccJerk-XYZ\n",
    "fBodyGyro-XYZ\n",
    "fBodyAccMag\n",
    "fBodyAccJerkMag\n",
    "fBodyGyroMag\n",
    "fBodyGyroJerkMag\n",
    "\n",
    "The set of variables that were estimated from these signals are: \n",
    "\n",
    "mean(): Mean value\n",
    "std(): Standard deviation\n",
    "mad(): Median absolute deviation \n",
    "max(): Largest value in array\n",
    "min(): Smallest value in array\n",
    "sma(): Signal magnitude area\n",
    "energy(): Energy measure. Sum of the squares divided by the number of values. \n",
    "iqr(): Interquartile range \n",
    "entropy(): Signal entropy\n",
    "arCoeff(): Autorregresion coefficients with Burg order equal to 4\n",
    "correlation(): correlation coefficient between two signals\n",
    "maxInds(): index of the frequency component with largest magnitude\n",
    "meanFreq(): Weighted average of the frequency components to obtain a mean frequency\n",
    "skewness(): skewness of the frequency domain signal \n",
    "kurtosis(): kurtosis of the frequency domain signal \n",
    "bandsEnergy(): Energy of a frequency interval within the 64 bins of the FFT of each window.\n",
    "angle(): Angle between to vectors.\n",
    "\n",
    "Additional vectors obtained by averaging the signals in a signal window sample. These are used on the angle() variable:\n",
    "\n",
    "gravityMean\n",
    "tBodyAccMean\n",
    "tBodyAccJerkMean\n",
    "tBodyGyroMean\n",
    "tBodyGyroJerkMean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Data and Browse\n",
    "- Data is located in <project_root>/exercises/data/samsungdata.csv\n",
    "    - For solutions notebook, the relative file path is '../data/samsungdata.csv'\n",
    "    - For exercise notebook, the relative path is './data/samsungdata.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import seaborn as sbn\n",
    "import pandas as pd\n",
    "X_raw = pd.read_csv('https://github.com/gte620v/PracticalDataScience/raw/master/exercises/data/samsungdata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, take a look at the data and get acquainted\n",
    "For example, you could do things like\n",
    "```python\n",
    "X_raw.shape\n",
    "```\n",
    "\n",
    "```python\n",
    "X_raw.head()\n",
    "```\n",
    "\n",
    "For a more detailed overview of your data, look at\n",
    "```python\n",
    "X_raw.describe()\n",
    "```\n",
    "\n",
    "In particular, browse to see if there are any variables in your data that are NOT numerical sensor measurements to be used for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning up the data and getting ready for Machine Learning\n",
    "We'll do a very crude data cleaning step, just enough to get the data in a usable form.\n",
    "\n",
    "There are two columns, \"Unnamed: 0\", \"subject\" and \"activity\" that are categorical and/or not useful.\n",
    "\n",
    "1. The 'activity' column contains the targets to be used for classification (activity categories). Extract that into a separate variable.\n",
    "Hint:\n",
    "```python\n",
    "truth_har = X_raw['activity']\n",
    "```\n",
    "Take a look at the distribution of the activity class labels.\n",
    "\n",
    "2. Do a similar analysis for the 'subject' column.\n",
    "\n",
    "3. Remove the 3 columns 'Unnamed: 0', 'subject', and 'activity' from X_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a RF Classifier as a Black Box\n",
    "Some observations about this problem\n",
    "- What if we don't know much about Human Activity Recognition?\n",
    "- What if we don't know a lot about the sensors (accelerometers, gyroscopes, etc)?\n",
    "- Can we get some results very fast that will give us reasonably good performance?\n",
    "\n",
    "Make a pass at this problem using Random Forest Classifiers. Pick some reasonable defaults and test your algorithm.\n",
    "```python\n",
    "import sklearn.ensemble as ens # check out: ens.RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the sklearn helper function 'train_test_split' to split your matrix/data into test and training set. Set aside 20% of the data for testing final model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select some reasonable parameter choices for your RandomForestClassifier.\n",
    "\n",
    "For example,\n",
    "```python\n",
    "rf_classifier = ens.RandomForestClassifier(max_features=<choose one>, n_estimators=<choose>, oob_score=True)\n",
    "```\n",
    "\n",
    "Note the following parameters are key to exploring the bias/variance tradeoff of Random Forests.\n",
    "- max_features : number of features to be randomly selected in the construction of individual trees\n",
    "    - Recommended to be approx $\\sqrt{N_{features}}$\n",
    "- n_estimators : total number of trees to be built for the ensemble. Pick some value between 25 and 500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model to the training data, and calculate the OOB error/accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, calculate the test set error for this model.\n",
    "- How is the performance?\n",
    "- How close was the out-of-bag error to the test set error? Any insights to gain there?\n",
    "\n",
    "Hint: you can make predictions on the test set like this:\n",
    "```python\n",
    "m = rf.fit(X_train,y_train)\n",
    "y_test_predict = m.predict(X_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF Classifier Hyper-parameter Tuning\n",
    "We were able to achieve reasonably good performance, with no application of domain knowledge, in the previous example. This is an impressive feat. However, how can we really know if this performance is good? We only arbitrarily selected a single parameter setting?\n",
    "\n",
    "Random Forests have a variety of parameters that can be tuned before training the model. These parameters fall into a couple categories:\n",
    "1. Changing the loss functions used to construct individual decision trees (we will not consider this)\n",
    "2. Modifying the construction process of the Ensemble Learner.\n",
    "\n",
    "As we learned in the lecture on Ensemble Learning and Random Forests, the trick to high performance is\n",
    "1. Having the ability to create a large number of trees (wisdom of the crowds)\n",
    "2. Ensuring each tree has 'novelty', in the sense of statistical independence from the other trees.\n",
    "3. Making each tree satisfy the \"Weak Learner\" condition for convergence\n",
    "3. Note 1 and 2 above are in conflict with each other. The more trees we construct, the hard it is to maintain statistical independence from the previous trees.\n",
    "\n",
    "The two Random Forest hyper-parameters that align with our wishes are:\n",
    "- max_features\n",
    "    - Proper subset of features to be sampled in construction of the tree.\n",
    "    - By having this number be much less than the total number of features, this introduces novelty and statistical independence between trees in the ensemble.\n",
    "- n_estimators\n",
    "    - The number of trees to construct.\n",
    "    \n",
    "Before we can begin a grid search, we need to get a sense for how much computational power we have behind the scenes to train a single model. This will help us estimate the time we need to complete a grid search.\n",
    "\n",
    "As a suggestion, use max_features=25 and n_estimators=500 to get a ballpark estimate.\n",
    "\n",
    "\n",
    "```python\n",
    "%%time\n",
    "rf_benchmark1 = ens.RandomForestClassifier(max_features=25, n_estimators=500, oob_score=True)\n",
    "rf_benchmark1.fit(X_train,y_train)\n",
    "```\n",
    "\n",
    "**FIGURE OUT HOW MANY PARAMETER COMBINATIONS YOU WILL BE ABLE TO EXPLORE IN APPROX 3min OF COMPUTATION TIME**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the limiting performance factors in the previous example is that all the computations were run on a single CPU. To see this, open up your shell, and run htop in a tmux session. Then, rerun the above code segment and which the CPU usage and load.\n",
    "```bash\n",
    "user@host:~/$ htop\n",
    "```\n",
    "We can check the number of cores on the machine that's hosting our notebook, along with the specs of those processors by running the following shell command in our notebook:\n",
    "```\n",
    "!cat /proc/cpuinfo\n",
    "```\n",
    "\n",
    "From this, we can see colaboratory runs on 2 vCPUs.\n",
    "\n",
    "Let's modify training to use ALL CPUs, and benchmark the progress. We do this by adding the parameter \"n_jobs\" when we construct the Random Forest (specifying the number of cores to use in training). If n_jobs=-1, all available cores are used in model training.\n",
    "```python\n",
    "%%time\n",
    "rf_benchmark2 = ens.RandomForestClassifier(max_features=25, n_estimators=500, oob_score=True, n_jobs=-1)\n",
    "rf_benchmark2.fit(X_train,y_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the measured performance, create a grid search to find an 'optimal' mode over a variety of parameter combinations. Here's a suggestion for how this may look:\n",
    "```python\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "model_template = ens.RandomForestClassifier(random_state=123)\n",
    "param_grid = { \n",
    "    'n_estimators': [<fill in here>],\n",
    "    'max_features': [<fill in here>],\n",
    "}\n",
    "rf_gridCV = GridSearchCV(estimator=model_template,param_grid=param_grid,n_jobs=-1,cv=2)\n",
    "rf_gridCV.fit(X_train,y_train)\n",
    "rf_gridCV.best_params_\n",
    "rf_gridCV.best_score_\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, evaluate the 'best' Random Forest on the test set.\n",
    "```python\n",
    "yp = rf_gridCV.best_estimator_.predict(X_test)\n",
    "accuracy_score(y_pred=yp,y_true=y_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turbo-Charging RF Classifier Hyper-parameter Tuning\n",
    "Now we will see the power of elastic computing resources in their ability to help us train a high performing model with minimal code changes. We'll make 3 changes to our hyper-parameter tuning grid search.\n",
    "1. We'll stop our Google Compute instance, and **edit the specs of the machine to be MUCH more powerful**\n",
    "    - We'll be able to restart our instance without needing to re-run our entire setup process. POWERFUL productivity booster!\n",
    "2. We'll add-in 5-fold cross validation (CV) into the model selection/grid search process. \n",
    "    - CV turns out to be a better estimator of validation set error than out-of-bag error. OOB error is a neat computational trick that approximates test set error. However, it's a biases estimator and can lead to overfitting the model. We are going for RAW HORSEPOWER AND PERFORMANCE here.\n",
    "3. We'll expand our grid search to try a larger variety of model topologies.\n",
    "\n",
    "```python\n",
    "model_template = ens.RandomForestClassifier(random_state=321)\n",
    "param_grid = { \n",
    "    'n_estimators': [<fill in here>],\n",
    "    'max_features': [<fill in here>],\n",
    "}\n",
    "rf_gridCV = GridSearchCV(estimator=model_template,param_grid=param_grid,n_jobs=-1,cv=5)\n",
    "rf_gridCV.fit(X_train,y_train)\n",
    "rf_gridCV.best_params_\n",
    "rf_gridCV.best_score_\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
