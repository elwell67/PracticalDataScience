{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Learning Using Random Forests\n",
    "This a lab session to use tree ensembles, in particular Random Forests, to build a interesting classifier related to human activity recognition using mobile phone data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Documentation about the Data Sources\n",
    "\n",
    "The features selected for this UCI database come from the accelerometer and gyroscope 3-axial raw signals tAcc-XYZ and tGyro-XYZ. These time domain signals (prefix 't' to denote time) were captured at a constant rate of 50 Hz. Then they were filtered using a median filter and a 3rd order low pass Butterworth filter with a corner frequency of 20 Hz to remove noise. Similarly, the acceleration signal was then separated into body and gravity acceleration signals (tBodyAcc-XYZ and tGravityAcc-XYZ) using another low pass Butterworth filter with a corner frequency of 0.3 Hz. \n",
    "\n",
    "Subsequently, the body linear acceleration and angular velocity were derived in time to obtain Jerk signals (tBodyAccJerk-XYZ and tBodyGyroJerk-XYZ). Also the magnitude of these three-dimensional signals were calculated using the Euclidean norm (tBodyAccMag, tGravityAccMag, tBodyAccJerkMag, tBodyGyroMag, tBodyGyroJerkMag). \n",
    "\n",
    "Finally a Fast Fourier Transform (FFT) was applied to some of these signals producing fBodyAcc-XYZ, fBodyAccJerk-XYZ, fBodyGyro-XYZ, fBodyAccJerkMag, fBodyGyroMag, fBodyGyroJerkMag. (Note the 'f' to indicate frequency domain signals). \n",
    "\n",
    "These signals were used to estimate variables of the feature vector for each pattern:  \n",
    "'-XYZ' is used to denote 3-axial signals in the X, Y and Z directions.\n",
    "\n",
    "tBodyAcc-XYZ\n",
    "tGravityAcc-XYZ\n",
    "tBodyAccJerk-XYZ\n",
    "tBodyGyro-XYZ\n",
    "tBodyGyroJerk-XYZ\n",
    "tBodyAccMag\n",
    "tGravityAccMag\n",
    "tBodyAccJerkMag\n",
    "tBodyGyroMag\n",
    "tBodyGyroJerkMag\n",
    "fBodyAcc-XYZ\n",
    "fBodyAccJerk-XYZ\n",
    "fBodyGyro-XYZ\n",
    "fBodyAccMag\n",
    "fBodyAccJerkMag\n",
    "fBodyGyroMag\n",
    "fBodyGyroJerkMag\n",
    "\n",
    "The set of variables that were estimated from these signals are: \n",
    "\n",
    "mean(): Mean value\n",
    "std(): Standard deviation\n",
    "mad(): Median absolute deviation \n",
    "max(): Largest value in array\n",
    "min(): Smallest value in array\n",
    "sma(): Signal magnitude area\n",
    "energy(): Energy measure. Sum of the squares divided by the number of values. \n",
    "iqr(): Interquartile range \n",
    "entropy(): Signal entropy\n",
    "arCoeff(): Autorregresion coefficients with Burg order equal to 4\n",
    "correlation(): correlation coefficient between two signals\n",
    "maxInds(): index of the frequency component with largest magnitude\n",
    "meanFreq(): Weighted average of the frequency components to obtain a mean frequency\n",
    "skewness(): skewness of the frequency domain signal \n",
    "kurtosis(): kurtosis of the frequency domain signal \n",
    "bandsEnergy(): Energy of a frequency interval within the 64 bins of the FFT of each window.\n",
    "angle(): Angle between to vectors.\n",
    "\n",
    "Additional vectors obtained by averaging the signals in a signal window sample. These are used on the angle() variable:\n",
    "\n",
    "gravityMean\n",
    "tBodyAccMean\n",
    "tBodyAccJerkMean\n",
    "tBodyGyroMean\n",
    "tBodyGyroJerkMean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Data and Browse\n",
    "- Data is located in <project_root>/exercises/data/samsungdata.csv\n",
    "    - For solutions notebook, the relative file path is '../data/samsungdata.csv'\n",
    "    - For exercise notebook, the relative path is './data/samsungdata.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import seaborn as sbn\n",
    "import pandas as pd\n",
    "X_raw = pd.read_csv('../data/samsungdata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, take a look at the data and get acquainted\n",
    "For example, you could do things like\n",
    "```python\n",
    "X_raw.shape\n",
    "```\n",
    "\n",
    "```python\n",
    "X_raw.head()\n",
    "```\n",
    "\n",
    "For a more detailed overview of your data, look at\n",
    "```python\n",
    "X_raw.describe()\n",
    "```\n",
    "\n",
    "In particular, browse to see if there are any variables in your data that are NOT numerical sensor measurements to be used for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning up the data and getting ready for Machine Learning\n",
    "We'll do a very crude data cleaning step, just enough to get the data in a usable form.\n",
    "\n",
    "There are two columns, \"Unnamed: 0\", \"subject\" and \"activity\" that are categorical and/or not useful.\n",
    "\n",
    "1. The 'activity' column contains the targets to be used for classification (activity categories). Extract that into a separate variable.\n",
    "Hint:\n",
    "```python\n",
    "truth_har = X_raw['activity']\n",
    "```\n",
    "Take a look at the distribution of the activity class labels.\n",
    "\n",
    "2. Do a similar analysis for the 'subject' column.\n",
    "\n",
    "3. Remove the 3 columns 'Unnamed: 0', 'subject', and 'activity' from X_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interesting non-numerical variables to check\n",
    "subjects = X_raw['subject']\n",
    "truth_har = X_raw['activity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbn.countplot(truth_har)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbn.countplot(subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw = X_raw.drop(['Unnamed: 0','subject','activity'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a RF Classifier as a Black Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.ensemble as ens\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ... First we need to split into training and validation sets\n",
    "shuffle_seed = 31459\n",
    "test_slice = 0.20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_raw,truth_har, test_size=test_slice, random_state=shuffle_seed, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... Some initial paramaters just to try it out\n",
    "nfeatures = X_train.shape[1]\n",
    "nf_sample = np.int(np.round(np.sqrt(nfeatures)))\n",
    "ntrees = 500\n",
    "rf = ens.RandomForestClassifier(max_features=nf_sample, n_estimators=500, oob_score=True, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "m1 = rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF Classifier Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ens.RandomForestClassifier(random_state=123)\n",
    "param_grid = { \n",
    "    'n_estimators': [50,100,250,500],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_gridCV = GridSearchCV(estimator=rf,param_grid=param_grid,n_jobs=-1,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rf_gridCV.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_gridCV.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_gridCV.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_gridCV.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
