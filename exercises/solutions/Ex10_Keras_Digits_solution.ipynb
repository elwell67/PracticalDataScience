{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "exercises/solutions/Ex10_Keras_Digits_solution.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "RTp0tNsv2UIb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Keras Digit Demonstration\n",
        "\n",
        "In this exercise, we will use a CNN to classify hand-written digits using Keras.\n",
        "\n",
        "### Imports"
      ]
    },
    {
      "metadata": {
        "id": "jthftiEwBmQd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelBinarizer, minmax_scale\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (15.0, 3.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lx-9I9yd2q1X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Install libraries we will need to visualize our DNN"
      ]
    },
    {
      "metadata": {
        "id": "iRALHelOBnDY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install pydot\n",
        "!apt-get install -yq graphviz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_0TMSTiV2wvJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Keras Libraries and Modules"
      ]
    },
    {
      "metadata": {
        "id": "iGs5kkPvBofe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, Lambda, Concatenate\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from keras import backend as K\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SI6T4P4I20yL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Import dataset from Keras\n",
        "\n",
        "We create a combined dataset with test and training rows.  We will features in `model.fit` to create a validation dataset later in the exercise.\n",
        "\n",
        "Notice that the digits are 4D tensors.  The first dimension is the \"row\" or sample image index.  The next to dimensions are the spatial dimensions, x/y.  The last dimension is for color channels.  In this case, we have one color channels since the images are black and white."
      ]
    },
    {
      "metadata": {
        "id": "Hh_He4SKBs8w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(x_train_, y_train_), (x_test_, y_test_) = mnist.load_data()\n",
        "X = np.vstack([x_train_,x_test_])[...,np.newaxis]\n",
        "y_ = np.hstack([y_train_,y_test_])\n",
        "label_coder = LabelBinarizer()\n",
        "\n",
        "label_coder.fit(y_)\n",
        "\n",
        "Y = label_coder.transform(y_)\n",
        "\n",
        "y_test = label_coder.transform(y_test_)\n",
        "y_train = label_coder.transform(y_train_)\n",
        "x_test = x_test_[...,np.newaxis]\n",
        "x_train = x_train_[...,np.newaxis]\n",
        "\n",
        "X.shape, Y.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qKJjtUap3c-J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Plot a random row"
      ]
    },
    {
      "metadata": {
        "id": "wurDYsi2BvUH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ind = np.random.choice(range(X.shape[0]))\n",
        "plt.imshow(X[ind,...,0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TA7yEs1B38z1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Check the histogram of labels"
      ]
    },
    {
      "metadata": {
        "id": "eeUcQoWXBw-h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.hist(y_);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "psqTTz774GC3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Simple Fully Connected Model\n",
        "\n",
        "We start with a three-layer fully-connected ANN. \n",
        "\n",
        "We have a categorical classification problem which means that our network should classify the image as only of the ten classes (0-9).  Because of this, we need the output activation function to be `softmax`, which approximates a probability distribution where the output layer outputs all sum to 1."
      ]
    },
    {
      "metadata": {
        "id": "dQNDQxYeB9No",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_ = Input((28,28,1))\n",
        "\n",
        "x = input_\n",
        "x = Flatten()(x)\n",
        "x = Dense(100,activation='relu')(x)\n",
        "x = Dense(100,activation='relu')(x)\n",
        "\n",
        "\n",
        "x = Dense(10, activation='softmax')(x)\n",
        "\n",
        "\n",
        "\n",
        "model = Model(input_, x)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cHbGkOFW441J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Check the model weights\n",
        "\n",
        "The model is initialized with random weights and can be executed before training.  Let's use Keras to examine the model weights.\n",
        "\n",
        "#### Model layers as a list"
      ]
    },
    {
      "metadata": {
        "id": "wqO1rBJ55HE6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cyw4jIOn5nSQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Model weights in the last layer\n",
        "\n",
        "Each layer has a NxM mapping matrix of weights and M bias values."
      ]
    },
    {
      "metadata": {
        "id": "r5URZxHO5MXZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.layers[-1].weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z59-oQ8750Z4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Use `K.eval` to view weight values"
      ]
    },
    {
      "metadata": {
        "id": "8Mk6pa415hLY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "K.eval(model.layers[-1].weights[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "osC5VmoA57WB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Plot weights"
      ]
    },
    {
      "metadata": {
        "id": "eAT1gtpN5RPr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(K.eval(model.layers[-1].weights[0]),aspect='auto')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uuevEaSG6AHY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## We can also run the untrained model on the first two inputs"
      ]
    },
    {
      "metadata": {
        "id": "Aaj-WfynIhaM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(X[0,...,0])\n",
        "plt.show()\n",
        "plt.imshow(X[1,...,0])\n",
        "activations = model.predict(X[:2,...])\n",
        "\n",
        "activations.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p8a3TvCn7SAl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "plt.plot(activations.T,'s')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tuHA7RKe7o7p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train It!"
      ]
    },
    {
      "metadata": {
        "id": "RBQmnazU7rDg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', \n",
        "              optimizer=keras.optimizers.Adam(lr=.001),\n",
        "              metrics=['accuracy'])\n",
        "model.fit(x_train,y_train, \n",
        "          batch_size=400, \n",
        "          validation_data=(x_test,y_test),\n",
        "          epochs=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1fMl77n3761X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Check Trained model activations"
      ]
    },
    {
      "metadata": {
        "id": "iH0_eidb7-BE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "activations = model.predict(x_test, verbose=1)\n",
        "plt.imshow(x_test[0,...,0])\n",
        "plt.show()\n",
        "plt.plot(activations[0,:],'s')\n",
        "plt.show()\n",
        "plt.imshow(x_test[1,...,0])\n",
        "plt.show()\n",
        "plt.plot(activations[1,:],'s')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZdzEikItC3j3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "def plot_confusion_matrix(y_test, y_pred, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.rcParams['figure.figsize'] = (10.0, 10.0)\n",
        "    cm = confusion_matrix(y_test, y_pred,)\n",
        "    np.set_printoptions(precision=2)\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    # print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    \n",
        "    plt.rcParams['figure.figsize'] = (15.0, 3.0)\n",
        "\n",
        "\n",
        "plot_confusion_matrix(y_test_, label_coder.inverse_transform(activations), label_coder.classes_);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e_hLZpgM8vz5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# CNN Model\n",
        "\n",
        "65% accurcay is impressive for such a simple model, but it isn't really usable.  In order to make the next level of improvement, we need to use convolutional layers."
      ]
    },
    {
      "metadata": {
        "id": "PPV195REIJAP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_ = Input((28,28,1))\n",
        "\n",
        "x = Conv2D(32, (3,3), activation='relu')(input_)\n",
        "x = Conv2D(64, (3,3), activation='relu')(x)\n",
        "x = MaxPooling2D(pool_size=(2,2))(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(100,activation='relu')(x)\n",
        "\n",
        "x = Dense(10, activation='softmax')(x)\n",
        "\n",
        "cnn_model = Model(input_, x)\n",
        "cnn_original_weights = cnn_model.get_weights()\n",
        "cnn_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8vgwrtHE9bnj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Examine the convolution kernel values\n",
        "\n",
        "Just as we did with the fully connected weight matrix, we can extract and visualize the weight matrix for the convolution kernals."
      ]
    },
    {
      "metadata": {
        "id": "OepMwEd0I47L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "kerns = K.eval(cnn_model.layers[1].weights[0])\n",
        "kerns.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hWnCcF19J-wW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.rcParams['figure.figsize'] = (15.0, 15.0)\n",
        "nrow = 8; ncol = 4;\n",
        "fig, axs = plt.subplots(nrows=nrow, ncols=ncol)\n",
        "\n",
        "k = 0\n",
        "for ax in axs.reshape(-1): \n",
        "    ax.imshow(kerns[:,:,0,k])\n",
        "    k += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dh0U1ToU9zpp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Plot Layer Flow\n",
        "\n",
        "We can also plot the layer flow as a SVG"
      ]
    },
    {
      "metadata": {
        "id": "ubLjKRswCSl-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "SVG(model_to_dot(model,True,True).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "efb2BhFd9_Dh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Fit the CNN Model"
      ]
    },
    {
      "metadata": {
        "id": "nqZzXvWWCXKC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cnn_model.compile(loss='categorical_crossentropy', \n",
        "                  optimizer=keras.optimizers.Adam(lr=.001),\n",
        "                  metrics=['accuracy'])\n",
        "cnn_model.fit(x_train,y_train, \n",
        "              batch_size=100, \n",
        "              validation_data=(x_test,y_test),\n",
        "              epochs=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "joscyFZqAAkT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Predict Model Output\n"
      ]
    },
    {
      "metadata": {
        "id": "_1-vBrdyOqSU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_hat = cnn_model.predict(x_test,batch_size=200, verbose=1,)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AqyaGEwHAw02",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Plot Model Performance"
      ]
    },
    {
      "metadata": {
        "id": "-BFcYdkmA2Wf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(y_test_, label_coder.inverse_transform(y_hat), label_coder.classes_);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B1e7I7cFBEuT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Callbacks\n",
        "\n",
        "Keras has a convenient mechanism for taking actions in between epochs called \"callbacks\".  See https://keras.io/callbacks/ for details.\n",
        "\n",
        "### Learning rate schedule\n",
        "We are going to define a `LearningRateScheduler` callback, which will adjust the learning rate as we progress through epochs."
      ]
    },
    {
      "metadata": {
        "id": "K9D1ThdwTrwC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def lrs(epoch):\n",
        "    print(f'epoch = {epoch}')\n",
        "    lr = 0.001**(1+epoch/10)\n",
        "    print(f'lr = {lr}')\n",
        "    return lr\n",
        "\n",
        "calls = [LearningRateScheduler(lrs)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8ihdJFMhBycM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Now retrain with this callback"
      ]
    },
    {
      "metadata": {
        "id": "oeu4y8E5B9er",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cnn_model.set_weights(cnn_original_weights) # reset model\n",
        "cnn_model.compile(loss='categorical_crossentropy', \n",
        "                  optimizer=keras.optimizers.Adam(lr=.001),\n",
        "                  metrics=['accuracy'])\n",
        "cnn_model.fit(x_train,y_train, \n",
        "              batch_size=400, \n",
        "              validation_data=(x_test,y_test),\n",
        "              epochs=4,\n",
        "              callbacks=calls)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tIXWDYKmC64r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## We can also callback to tensorboard\n",
        "\n",
        "To set this up on colab, I followed the instructions at https://www.dlology.com/blog/quick-guide-to-run-tensorboard-in-google-colab/\n",
        "\n",
        "These instructions start tensorboard on this machine and tunnel to the tensorboard port so that we can hit the address externally."
      ]
    },
    {
      "metadata": {
        "id": "zP7LRBZ3-403",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LOG_DIR = './log2'\n",
        "! rm -rf $LOG_DIR\n",
        "\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "# Install\n",
        "! npm install -g localtunnel\n",
        "\n",
        "# Tunnel port 6006 (TensorBoard assumed running)\n",
        "get_ipython().system_raw('lt --port 6006 >> url.txt 2>&1 &')\n",
        "\n",
        "# Get url\n",
        "! cat url.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GSB1VR7F-5Jh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.callbacks import TensorBoard\n",
        "cnn_model.set_weights(cnn_original_weights) # reset model\n",
        "\n",
        "cnn_model.compile(loss='categorical_crossentropy', \n",
        "                  optimizer=keras.optimizers.Adam(lr=.001),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "\n",
        "tbCallBack = TensorBoard(log_dir='./log2/cnn_model/', histogram_freq=1,\n",
        "                         write_graph=True,\n",
        "                         write_grads=True,\n",
        "                         batch_size=400,\n",
        "                         write_images=True)\n",
        "\n",
        "cnn_model.fit(x_train,y_train, \n",
        "              batch_size=100, \n",
        "              validation_data=(x_test,y_test),\n",
        "              epochs=4,\n",
        "              callbacks=[tbCallBack, LearningRateScheduler(lrs)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_-RXrdpG_ALN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}